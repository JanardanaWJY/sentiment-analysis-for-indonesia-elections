# -*- coding: utf-8 -*-
"""Baseline model (without KD).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-eH8JOszPjaFSfp-QAjVUTGugb0D6YTZ

# **Global Needs**
"""

import torch
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

leRate = 3e-5
baSize = 16

"""# **IndoBert Lite (without KD)**"""

!pip install datasets

from transformers import AutoModelForSequenceClassification
from datasets import Dataset

# load lite model
lite_model = AutoModelForSequenceClassification.from_pretrained('indobenchmark/indobert-lite-base-p2', num_labels=2)

import json
# load tokenized data for lite model (only train and validation)
with open('lite_tokenized_data.json', 'r') as f:
    lite_tokenized_data = json.load(f)

train_dataset_lite = Dataset.from_dict(lite_tokenized_data['train'])
val_dataset_lite = Dataset.from_dict(lite_tokenized_data['val'])

from torch.utils.data import DataLoader
from torch.nn import CrossEntropyLoss

def collate_fn(batch):
    return {
        'input_ids': torch.stack([torch.tensor(item['input_ids']) for item in batch]),
        'attention_mask': torch.stack([torch.tensor(item['attention_mask']) for item in batch]),
        'labels': torch.tensor([item['labels'] for item in batch], dtype=torch.long)
    }

# DataLoader for train dataset with collate_fn
train_loader = DataLoader(
    train_dataset_lite,
    batch_size=baSize,
    shuffle=True,
    collate_fn=collate_fn
)
print(train_loader)

# DataLoader for validation dataset
val_loader = DataLoader(
    val_dataset_lite,
    batch_size=baSize,
    shuffle=False,  # no need to shuffle for validation
    collate_fn=collate_fn
)
print(val_loader)


# Define loss function with weighted loss
criterion = CrossEntropyLoss()

# Define optimizer
optimizer = torch.optim.AdamW(lite_model.parameters(), lr=leRate)

from sklearn.metrics import classification_report
# Early Stopping Params
best_val_loss = float('inf')
patience = 3
min_delta = 0.001
patience_counter = 0
best_baseline_model = None

lite_model.to(device)

# Training loop
for epoch in range(50):
    total_train_loss = 0
    lite_model.train()

    # Training phase
    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        # Forward pass
        outputs = lite_model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits

        # Compute loss
        loss = criterion(logits, labels)

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_train_loss += loss.item()

    # Validation phase
    lite_model.eval()
    total_val_loss = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            # Forward pass
            outputs = lite_model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits

            # Compute validation loss
            loss = criterion(logits, labels)
            total_val_loss += loss.item()

            # Collect predictions and true labels for evaluation
            preds = torch.argmax(logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate average losses and metrics
    avg_train_loss = total_train_loss / len(train_loader)
    avg_val_loss = total_val_loss / len(val_loader)

    print(f"Epoch {epoch + 1}")
    print(f"Training Loss: {avg_train_loss:.4f}")
    print(f"Validation Loss: {avg_val_loss:.4f}")
    print("Validation Metrics:")
    print(classification_report(all_labels, all_preds, target_names=['Positive', 'Negative']))

    # Early Stopping
    if avg_val_loss < best_val_loss - min_delta:
        best_val_loss = avg_val_loss
        patience_counter = 0
        # Save the best model
        save_dir = f"best_baseline_model_epoch_{epoch + 1}"
        lite_model.save_pretrained(save_dir)  # Save the model checkpoint
        best_baseline_model = lite_model  # Update the best model reference
    else:
        patience_counter += 1
        print(f"No improvement in validation loss for {patience_counter} epoch(s).")

        if patience_counter >= patience:
            print("Early stopping triggered.")
            break

def evaluate_model(model, dataset, collate_fn):
    model.to(device)
    model.eval()
    data_loader = DataLoader(dataset, batch_size=baSize, collate_fn=collate_fn)
    all_preds, all_labels = [], []

    for batch in data_loader:
        input_ids = torch.tensor(batch['input_ids']).to(device)
        attention_mask = torch.tensor(batch['attention_mask']).to(device)
        labels = torch.tensor(batch['labels']).to(device)

        with torch.no_grad():
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            preds = torch.argmax(outputs.logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return classification_report(all_labels, all_preds, target_names=['Positive', 'Negative'])

# load tokenized data for lite model (only test)
with open('lite_tokenized_data.json', 'r') as f:
    lite_tokenized_data = json.load(f)

test_dataset_lite = Dataset.from_dict(lite_tokenized_data['test'])

lite_without_KD = best_baseline_model

# Evaluasi lite no KD Model pada Testing Set
print("Evaluasi lite no KD  Model (Testing Set):")
print(evaluate_model(lite_without_KD, test_dataset_lite, collate_fn))